# 1. Базовые общие понятия машинного обучения и искусственного интеллекта: в чём их разница? Назовите основные виды машинного обучения.

**Искусственный интеллект (ИИ)** — попытки создать компьютерные программы, внешне подражающие поведению человеческого мышления.
> *Источник: Определение из вводной части курса (лекция 1).*

**Машинное обучение (МО)** — раздел искусственного интеллекта, занимающийся анализом данных, нахождением и извлечением из них зависимостей и закономерностей, и выработкой на их основе обоснованных решений.
> *Источник: Определение из вводной части курса (лекция 1).*

**Основные виды МО:**
- Обучение с учителем (supervised learning)
- Обучение без учителя (unsupervised learning)
- Обучение с подкреплением (reinforcement learning)

**Другие упомянутые виды:**
- Обучение с частичным привлечением учителя (semi-supervised learning)
- Самостоятельное обучение (self-supervised learning)
- Состязательное обучение (adversarial learning)
> *Источник: Классификация видов МО из лекции 1.*

---

# 2. Какова общая последовательность действий при создании системы машинного обучения (решателя)? В чём назначение каждой из этих операций?

1. **Определение и формализация задачи** — понять, что дано, что требуется, какими свойствами должно обладать решение.
2. **Выбор модели данных** — выбор вида аппроксимации или представления системы.
3. **Выбор представления данных** — от этого зависит точность, эффективность и интерпретируемость.
4. **Подготовка данных** — сбор, очистка, разделение на выборки.
5. **Инициализация параметров модели** — задание начальных значений.
6. **Задание метрик качества** — критерии оценки обучения.
7. **Обучение модели** — поиск оптимальных или субоптимальных параметров.
8. **Проверка качества модели** — оценка на тестовых данных, проверка устойчивости.
> *Источник: Общая схема разработки системы МО из лекции 1.*

---

# 3. Машинное обучение с учителем (supervised learning): чем оно отличается от других видов машинного обучения и что специфическое для него необходимо? Какими средствами это достигается?

**Отличие:** наличие размеченных данных (пар «объект–метка»).
**Формально:** дано множество пар \((x^{(i)}, y^{(i)})\), нужно аппроксимировать \(f: X \to Y\).
**Что необходимо:** размеченная обучающая выборка.
**Как получают:** ручная или автоматическая разметка, краудсорсинг, использование смежных данных.
> *Источник: Формулировка задачи обучения с учителем и обсуждение необходимости размеченных данных (лекция 1).*

---

# 4. Методы решения задач обучения с подкреплением (reinforcement learning). Опишите задачи, решаемые методами обучения с подкреплением.

**Цель:** максимизация кумулятивной награды через взаимодействие агента со средой.
**Методы:**
- **Q-learning:**
  \[
  Q_{i+1}(s_t, a_t) = Q_i(s_t, a_t) + \alpha [r_{t+1} + \gamma \max_{a'} Q_i(s_{t+1}, a') - Q_i(s_t, a_t)]
  \]
- **Deep Q-learning:** аппроксимация \(Q\) нейросетью.
- **SARSA:**
  \[
  Q_{i+1}(s_t, a_t) = Q_i(s_t, a_t) + \alpha [r_{t+1} + \gamma Q(s_{t+1}, a_{t+1}) - Q_i(s_t, a_t)]
  \]
> *Источник: Формулы и описание методов RL из лекции 1.*

**Задачи:** управление роботами, игры, автономные системы, рекомендации.
> *Источник: Примеры применения RL из лекции 1.*

---

# 5. Как подготавливают числовые и категориальные данные для использования в системах машинного обучения? Перечислите операции и их назначение. В чём принципиальная разница предобработки естественным образом числовых и категориальных данных?

**Общий конвейер:**
1. Сбор и объединение
2. EDA (анализ распределений, аномалий, зависимостей)
3. Обработка пропусков
4. Обработка выбросов (для числовых)
5. Нормализация/стандартизация (для числовых)
6. Кодирование категориальных признаков
7. Понижение размерности (опционально)
8. Разделение на обучающую/тестовую выборки
> *Источник: Общий пайплайн предобработки из лекций по подготовке данных.*

**Числовые данные:**
- Обработка пропусков (удаление, замена средним/медианой)
- Обработка выбросов (IQR, z-score)
- Масштабирование (стандартизация, min-max, robust scaling)
- Преобразование распределения (логарифмирование)

**Категориальные данные:**
- Обработка пропусков (замена модой, отдельная категория)
- Кодирование (label encoding, one-hot, target encoding, frequency encoding)
> *Источник: Методы предобработки числовых и категориальных данных из лекций по подготовке данных.*

**Разница:**
Числовые — работа с распределением и масштабом.
Категориальные — перевод категорий в числовую форму без потери смысла.
> *Источник: Итоговое сравнение подходов из лекций.*

---

# 6. К какому типу машинного обучения относится регрессия? Что такое регрессор? Какими свойствами хороший регрессор должен быть наделён? По каким параметрам судят о качестве регрессионной модели?

**Тип:** обучение с учителем.
**Регрессор:** модель, предсказывающая целевую переменную по объекту.
**Свойства хорошего регрессора:** высокая точность на новых данных, устойчивость, интерпретируемость.
**Метрики качества:** MAE, MSE, RMSE, R² (коэффициент детерминации).
> *Источник: Определение регрессии и обсуждение качества модели из раздела "Линейная регрессия".*

*Дополнительно из лекций:*
В лекциях подчеркивается, что хорошая модель должна не только давать точный прогноз, но и иметь значимые коэффициенты (низкие p-значения, узкие доверительные интервалы). Качество интегрально оценивается по R², а значимость отдельных регрессоров — по t-статистике и p-значениям.
> *Источник: Раздел "Характеристики модели и регрессоров".*

---

# 7. Опишите метод наименьших квадратов для линейной регрессии. Опишите и сравните методы ridge regression, LASSO и эластичной сети (elastic net). Для чего в них служит регуляризация?

**МНК:** минимизация суммы квадратов отклонений:
\[
\min \sum (y_i - (kx_i + b))^2
\]
> *Источник: Вывод формул для коэффициентов линейной регрессии методом МНК.*

**Регуляризованные методы:**
- **Ridge (L2):**
  \[
  \min \left( \sum (y_i - \hat{y}_i)^2 + \lambda \sum \beta_j^2 \right)
  \]
- **LASSO (L1):**
  \[
  \min \left( \sum (y_i - \hat{y}_i)^2 + \lambda \sum |\beta_j| \right)
  \]
- **Elastic Net (L1+L2):**
  \[
  \min \left( \sum (y_i - \hat{y}_i)^2 + \lambda_1 \sum |\beta_j| + \lambda_2 \sum \beta_j^2 \right)
  \]

**Назначение регуляризации:** борьба с переобучением, снижение влияния мультиколлинеарности, отбор признаков (в LASSO).
> *Источник: Раздел "Обработка мультиколлинеарности. Факторные переменные", где регуляризация упоминается как метод борьбы с последствиями мультиколлинеарности.*

---

# 8. Что такое переобучение при регрессии? В чём оно проявляется? Как с ним бороться?

**Переобучение:** модель хорошо описывает обучающие данные, но плохо обобщает на новые.
**Проявления:** высокие MSE/R² на обучающей выборке, низкие — на тестовой.
> *Источник: Обсуждение качества модели и обобщающей способности в разделах про R² и проверку моделей.*

**Методы борьбы:**
- Регуляризация (Ridge, LASSO, Elastic Net)
- Увеличение обучающей выборки
- Упрощение модели (уменьшение числа признаков)
- Кросс-валидация
> *Источник: Методы регуляризации и отбора переменных упоминаются как способы улучшения модели.*

---

# 9. Перечислите метрики качества моделей бинарной классификации.

- Accuracy (точность)
- Precision (точность положительного класса)
- Recall (полнота)
- F1-score (гармоническое среднее precision и recall)
- Confusion Matrix (матрица ошибок)
> *Источник: Раздел "Меры точности классификаторов".*

*Дополнительно из лекций:*
В лекциях подробно разбирается матрица ошибок (Confusion Matrix) с выделением True Positive (TP), False Positive (FP, ошибка I рода), False Negative (FN, ошибка II рода), True Negative (TN). Подчеркивается, что accuracy может вводить в заблуждение при несбалансированных классах, поэтому важны precision и recall.
> *Источник: Таблица 10 "Матрица ошибок бинарной классификации" и поясняющий текст.*

---

# 10. Задача снижения размерности. Метод главных компонент: идея и основные свойства.

**Идея:** преобразование исходных признаков в новые ортогональные (главные компоненты), максимизирующие дисперсию данных.
**Свойства:**
- Компоненты ортогональны
- Первая компонента объясняет наибольшую дисперсию
- Можно сократить размерность, сохранив заданный процент дисперсии (например, 95%)
- Чувствителен к масштабированию данных
> *Источник: Раздел "Добавление и исключение новых переменных. Метод главных компонент".*

*Дополнительно из лекций:*
Геометрическая интерпретация: поиск таких осей (компонент), чтобы разброс данных по ним был максимальным. Новые признаки линейно выражаются через старые. Часто используется для борьбы с проклятием размерности.
> *Источник: Геометрическое объяснение и цели использования PCA в том же разделе.*

---

# 11. Кластеризация. (Опишите методы агломеративной кластеризации, K-средних, DBSCAN). Как происходит оценка количества кластеров?

**Агломеративная кластеризация:** иерархический метод, начинающий с отдельных точек и последовательно объединяющий ближайшие кластеры. Результат — дендрограмма.
> *Источник: Описание иерархических алгоритмов и рисунок 11 (дендрограмма).*

**K-средних:** итеративный метод, минимизирующий внутрикластерное расстояние до центроидов. Шаги: 1) выбор центров, 2) отнесение объектов к ближайшему центру, 3) пересчет центров, 4) повтор.
> *Источник: Описание алгоритма k-means в разделе "Кластеризация".*

**DBSCAN:** кластеризация на основе плотности. Выделяет основные объекты (в гуще кластера), достижимые объекты и шум (выбросы). Параметры: радиус окрестности и minPts.
> *Источник: Подробное описание алгоритма DBSCAN и классификации объектов на рисунке 13.*

**Оценка числа кластеров:**
- Метод локтя (elbow method) по WCSS (within-cluster sum of squares)
> *Источник: Описание "принципа локтя" и рисунок 12.*

---

# 12. Принцип работы ансамблей решателей. Какие предъявляются требования к слабым решателям для возможности построения сильного решателя? Опишите принципы организации бэггинга (bootstrap aggregation).

**Принцип:** объединение предсказаний нескольких моделей для улучшения обобщения.
**Требования к слабым решателям:** точность > 0.5 (лучше случайного), разнообразие ошибок.
> *Источник: Теорема Кондорсе "о присяжных", приведенная в разделе "Усиление классификаторов".*

**Бэггинг:**
1. Обучение каждого классификатора на своей бутстрап-выборке (случайной подвыборке с возвращением).
2. Агрегация результатов (простое или взвешенное голосование).
**Цель:** уменьшение дисперсии ошибки.
> *Источник: Описание стратегии беггинга и схема на рисунке 9.*

*Дополнительно из лекций:*
Упоминается, что оптимальное число признаков для одного классификатора в ансамбле — sqrt(n), а объем обучающей выборки — 2/3 от общего числа объектов. Random Forest — пример алгоритма на основе бэггинга.
> *Источник: Рекомендации по параметрам в том же разделе.*

---

# 13. Объясните, что такое простое голосование, взвешенное голосование, комитет экспертов (mixture of experts) при создании ансамбля. Стекинг (stacking, stacked generalization), его основная идея и назначение.

**Простое голосование:** каждый классификатор имеет один голос, выбирается класс с большинством голосов.
**Взвешенное голосование:** голоса классификаторов взвешиваются по их качеству (частоте правильных ответов на обучающей выборке).
**Комитет экспертов:** разные модели (эксперты) специализируются на разных частях данных или типах задач, их решения комбинируются.
> *Источник: Обсуждение способов объединения классификаторов в разделе "Усиление классификаторов".*

**Стекинг:** использование метамодели (например, линейной регрессии), которая обучается на предсказаниях базовых моделей как на новых признаках. Назначение — улучшить итоговый прогноз, комбинируя сильные стороны разных алгоритмов.
> *Источник: ИИ*

---

# 14. Бустинг (boosting). Основные идеи и принципы работы AdaBoost (adaptive boosting, адаптивный бустинг).

**Идея:** последовательное обучение моделей, где каждая следующая уделяет больше внимания объектам, которые были ошибочно классифицированы предыдущими.
**Принципы работы AdaBoost:**
1. Начальные веса всех объектов обучающей выборки равны.
2. На каждой итерации:
   - Обучается слабый классификатор на данных с текущими весами.
   - Вычисляется его взвешенная ошибка.
   - Вычисляется вес этого классификатора в итоговом ансамбле (чем меньше ошибка, тем больше вес).
   - Увеличиваются веса объектов, которые были классифицированы неверно.
3. Итоговый классификатор — взвешенная сумма (или взвешенное голосование) всех слабых классификаторов.
> *Источник: Общее описание концепции бустинга и адаптивного изменения весов объектов в разделе "Усиление классификаторов".*

---

# 15. Бустинг (boosting). Основные идеи и принципы работы градиентного бустинга (gradient boost).

**Идея:** последовательная минимизация функции потерь через градиентный спуск в пространстве функций (моделей).
**Принципы работы:**
1. Начинаем с начального простого предсказания (например, константа, равная среднему значению целевой переменной).
2. На каждом шаге (для каждой добавляемой модели):
   - Вычисляются остатки (псевдо-остатки) — градиенты функции потерь по текущему предсказанию.
   - Новая слабая модель (часто дерево решений) обучается предсказывать эти остатки.
   - Предсказание этой модели, умноженное на коэффициент обучения (шаг), добавляется к текущему общему предсказанию.
3. Процесс повторяется заданное число раз или до сходимости.
**Ключевое отличие от AdaBoost:** явная минимизация дифференцируемой функции потерь, а не перевзвешивание объектов.
> *Источник: ИИ*

---

# 16. Балансирование наборов данных: проблема несбалансированных данных и методы её преодоления

**Проблема:** один класс (мажоритарный) значительно преобладает над другим (миноритарным), что приводит к смещению модели в сторону частого класса и плохому распознаванию редкого.
> *Источник: Пример с accuracy 90% для тривиального классификатора в разделе "Меры точности классификаторов".*

**Методы:**
- **Взвешивание классов (class weighting):** назначение большей штрафной стоимости за ошибку на объекте миноритарного класса в функции потерь.
- **Undersampling:** случайное удаление части объектов мажоритарного класса.
- **Oversampling:** дублирование объектов миноритарного класса или генерация синтетических примеров (например, SMOTE).
- **Использование метрик, устойчивых к дисбалансу:** F1-score, Precision-Recall AUC, Matthews Correlation Coefficient (MCC) вместо Accuracy.
> *Источник: Обсуждение недостатка accuracy и необходимости других метрик косвенно указывает на проблему дисбаланса. Конкретные методы балансировки являются стандартными и логично дополняют материал.*

---

# 17. Деревья решений. Процесс построения. Регуляризация деревьев решений.

**Процесс построения:**
1. Начиная с корневого узла, содержащего всю выборку.
2. Для каждого узла выбирается признак и пороговое значение, которые наилучшим образом разделяют данные в этом узле на два подмножества.
3. **Критерий разделения:** максимизация чистоты дочерних узлов. Чаще всего используются:
   - **Критерий Джини (Gini impurity):** мера расслоения.
   - **Информационный выигрыш (Information Gain)** на основе энтропии Шеннона: каждый вопрос должен максимально снижать неопределенность (энтропию) системы.
4. Процесс рекурсивно повторяется для каждого дочернего узла, пока не будет выполнено условие остановки.
> *Источник: Раздел "Дерево принятия решений", включая описание критериев Джини и энтропии.*

**Регуляризация (для борьбы с переобучением):**
- Ограничение максимальной глубины дерева (`max_depth`).
- Задание минимального числа объектов в листе (`min_samples_leaf`).
- Задание минимального числа объектов для разделения узла (`min_samples_split`).
- Ограничение максимального числа листьев (`max_leaf_nodes`).
- **Обрезка (pruning):** построение полного дерева с последующим удалением узлов, дающих незначительный прирост качества.
> *Источник: Упоминание параметров `max_leaf_nodes` и `max_depth` в Коде 4 и обсуждение переобучения.*

---

# 18. Что такое случайный лес (random forest)? Для чего в него введена случайность? В чём она состоит и как влияет на методы построения случайного леса?

**Случайный лес:** ансамбль решающих деревьев, построенный на принципах **бэггинга** (bootstrap aggregation) с добавлением **случайности в выборе признаков**.
> *Источник: Упоминание Random Forest как примера алгоритма на основе бэггинга в разделе "Усиление классификаторов".*

**Цель введения случайности:**
- Уменьшение **корреляции между деревьями** в ансамбле.
- Повышение **обобщающей способности** модели.
- Борьба с **переобучением**, которому подвержены отдельные глубокие деревья.

**В чём состоит случайность:**
1. **Bootstrap-выборки:** каждое дерево обучается на своей случайной подвыборке данных, взятой с возвращением из исходного набора. Это создает разнообразие обучающих множеств.
2. **Случайный выбор признаков:** при поиске лучшего разделения в каждом узле дерева рассматривается не весь набор признаков, а только случайное подмножество из них (обычно размером `sqrt(n_features)`).

**Влияние на построение:**
- Каждое дерево строится независимо и параллельно.
- Деревья могут быть построены глубокими (с низким смещением), так как высокая дисперсия их ошибок затем усредняется в ансамбле.
- Итоговый прогноз формируется путем **усреднения** (для регрессии) или **голосования** (для классификации) предсказаний всех деревьев.
> *Источник: Объединение принципов бэггинга (раздел "Усиление классификаторов") и идеи случайного подмножества признаков, упомянутой в том же разделе.*

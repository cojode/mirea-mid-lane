### 1. Базовые общие понятия машинного обучения и искусственного интеллекта: в чём их разница? Назовите основные виды машинного обучения.

**Искусственный интеллект (ИИ)** — попытки создать компьютерные программы, внешне подражающие поведению человеческого мышления.
> *Источник: Определение из вводной части курса (лекция 1).*

В ИИ есть разделы: машинное обучение, обработка естественного языка, экспертные системы, зрение, речь, планирование и роботизация.

**Машинное обучение (МО)** — раздел искусственного интеллекта, занимающийся анализом данных, нахождением и извлечением из них зависимостей и закономерностей, и выработкой на их основе обоснованных решений.
> *Источник: Определение из вводной части курса (лекция 1).*

**Основные виды МО:**
- Обучение с учителем (supervised learning)
- Обучение без учителя (unsupervised learning)
- Обучение с подкреплением (reinforcement learning)

**Другие упомянутые виды:**
- Обучение с частичным привлечением учителя (semi-supervised learning)
- Самостоятельное обучение (self-supervised learning)
- Состязательное обучение (adversarial learning)
> *Источник: Классификация видов МО из лекции 1.*

---

### 2. Какова общая последовательность действий при создании системы машинного обучения (решателя)? В чём назначение каждой из этих операций?


1. **Определение и формализация задачи** 
   * что дано (объекты, признаки, объем данных, качество)
   * что требуется (классификация задачи, целевая переменная)
   * какими свойствами должно обладать решение (точность, качество, ограничения)
2. **Выбор модели данных**
   * выбор вида аппроксимации
   * представления системы
3. **Выбор представления данных** — от этого зависит точность, эффективность и интерпретируемость.
4. **Подготовка данных** — сбор, очистка, разделение на выборки.
5. **Инициализация параметров модели** — задание начальных значений.
6. **Задание метрик качества** — критерии оценки обучения.
7. **Обучение модели** — поиск оптимальных или субоптимальных параметров.
8. **Проверка качества модели** — оценка на тестовых данных, проверка устойчивости.
> *Источник: Общая схема разработки системы МО из лекции 1.*

Эта последовательность действий является итеративной, т.е. подразумевается перезапуск пунктов при неудаче на любом из этапов.

Стоит добавить в эту модель нулевой пункт: 

0. **Проверка осмысленности и контекста задачи**:
   * определить бизнес-цель и критерии успеха
   * наличие осмысленной зависимости(может ли эксперт решить задачу? нет ли тривиального решения?)
   * определение ограничения и требований


---

### 3. Машинное обучение с учителем (supervised learning): чем оно отличается от других видов машинного обучения и что специфическое для него необходимо? Какими средствами это достигается?

Обучение с учителем (supervised learning) — это задачи, в которых есть некоторый правильный ответ, целевая переменная, которую нужно предсказать. Датасет
здесь выглядит как $D = {(x_n,y_n)}$, то есть каждая точка датасета —
это пара из входа xn (вектора признаков) и выхода yn, той самой целевой переменной. 

Задачи обучения с учителем условно делятся на два класса в зависимости
от того, какой природы целевая переменная y: если она непрерывная, например
$y ∈ R$, то это задача регрессии, а если дискретная, то есть вход $x$ нужно определить в один из нескольких классов, это задача классификации.

> *Источник: Сергей Николенко "Машинное обучение: основы"*

**Отличие:** наличие размеченных данных (пар «объект–метка»).

**Формально:** дано множество пар $(x_i, y_i)$, нужно аппроксимировать $f: X \to Y$.

**Что необходимо:** размеченная обучающая выборка.

**Как получают:** ручная или автоматическая разметка, краудсорсинг, использование смежных данных.
> *Источник: Формулировка задачи обучения с учителем и обсуждение необходимости размеченных данных (лекция 1).*

---

### 4. Методы решения задач обучения с подкреплением (reinforcement learning). Опишите задачи, решаемые методами обучения с подкреплением.

**Цель:** максимизация кумулятивной награды через взаимодействие агента со средой.

**Методы:**
- **Q-learning:**
  ```math
  Q_{i+1}(s_t, a_t) = Q_i(s_t, a_t) + \alpha [r_{t+1} + \gamma \max_{a'} Q_i(s_{t+1}, a') - Q_i(s_t, a_t)]
  ```
- **Deep Q-learning:** аппроксимация $Q$ нейросетью.
- **SARSA:**
  ```math
  Q_{i+1}(s_t, a_t) = Q_i(s_t, a_t) + \alpha [r_{t+1} + \gamma Q(s_{t+1}, a_{t+1}) - Q_i(s_t, a_t)]
  ```
> *Источник: Формулы и описание методов RL из лекции 1.*

**Задачи:** управление роботами, игры, автономные системы, рекомендации.
> *Источник: Примеры применения RL из лекции 1.*


$Q(s, a)$ — ожидаемое $Q$-значение состояния и действия,

$r$ — немедленная награда, полученная после выполнения действия $a$ из состояния $s$

$γ$ — коэффициент дисконтирования, который представляет собой важность будущих наград (обычно значение между 0 и 1),

$max_{a'} Q_i(s_{t+1}, a')$ — максимальное Q-значение для всех возможных действий a' из следующего состояния s'.

---

### 5. Как подготавливают числовые и категориальные данные для использования в системах машинного обучения? Перечислите операции и их назначение. В чём принципиальная разница предобработки естественным образом числовых и категориальных данных?

**Общий конвейер:**
1. Сбор и объединение
2. EDA (анализ распределений, аномалий, зависимостей)
3. Обработка пропусков
4. Обработка выбросов (для числовых)
5. Нормализация/стандартизация (для числовых)
6. Кодирование категориальных признаков
7. Понижение размерности (опционально)
8. Разделение на обучающую/тестовую выборки
> *Источник: Общий пайплайн предобработки из лекций по подготовке данных.*

**Числовые данные:**
- Обработка пропусков (удаление, замена средним/медианой)
- Обработка выбросов (IQR, z-score)
- Масштабирование (стандартизация, min-max, robust scaling)
- Преобразование распределения (логарифмирование)

**Категориальные данные:**
- Обработка пропусков (замена модой, отдельная категория)
- Кодирование (label encoding, one-hot, target encoding, frequency encoding)
> *Источник: Методы предобработки числовых и категориальных данных из лекций по подготовке данных.*

**Разница:**
Числовые — работа с распределением и масштабом.
Категориальные — перевод категорий в числовую форму без потери смысла.
> *Источник: Итоговое сравнение подходов из лекций.*

---

### 6. К какому типу машинного обучения относится регрессия? Что такое регрессор? Какими свойствами хороший регрессор должен быть наделён? По каким параметрам судят о качестве регрессионной модели?

**Тип:** обучение с учителем.

**Регрессор:** модель, предсказывающая целевую переменную по объекту.

**Свойства хорошего регрессора:** высокая точность на новых данных, устойчивость, интерпретируемость.

> *Источник: Определение регрессии и обсуждение качества модели из раздела "Линейная регрессия".*


**Метрики качества:**

```math
MSE=\frac{1}{n}\sum_{i=1}^{n}{(a(x_i)−y_i)^2}
```
MSE применяется в ситуациях, когда нам надо подчеркнуть большие ошибки и выбрать модель, которая дает меньше больших ошибок прогноза. Грубые ошибки становятся заметнее за счет того, что ошибку прогноза мы возводим в квадрат. И модель, которая дает нам меньшее значение среднеквадратической ошибки, можно сказать, что что у этой модели меньше грубых ошибок.
```math
MAE=\frac{1}{n}\sum_{i=1}^{n}{|a(x_i)−y_i|}
```
Среднеквадратичный функционал сильнее штрафует за большие отклонения по сравнению со среднеабсолютным, и поэтому более чувствителен к выбросам. При использовании любого из этих двух функционалов может быть полезно проанализировать, какие объекты вносят наибольший вклад в общую ошибку — не исключено, что на этих объектах была допущена ошибка при вычислении признаков или целевой величины.
```math
R^2=1 - \frac{MSE}{\sum_{i=1}^{n}{(\hat{y}−y_i)^2}}
```
Коэффициент детерминации измеряет долю дисперсии, объясненную моделью, в общей дисперсии целевой переменной. Фактически, данная мера качества — это нормированная среднеквадратичная ошибка. Если она близка к единице, то модель хорошо объясняет данные, если же она близка к нулю, то прогнозы сопоставимы по качеству с константным предсказанием.

> *Источник: [ИФМО](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%D1%85_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8_%D0%B8_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8#.D0.9E.D1.86.D0.B5.D0.BD.D0.BA.D0.B8_.D0.BA.D0.B0.D1.87.D0.B5.D1.81.D1.82.D0.B2.D0.B0_.D1.80.D0.B5.D0.B3.D1.80.D0.B5.D1.81.D1.81.D0.B8.D0.B8)*

*Дополнительно из лекций:*
В лекциях подчеркивается, что хорошая модель должна не только давать точный прогноз, но и иметь значимые коэффициенты (низкие p-значения, узкие доверительные интервалы). Качество интегрально оценивается по R², а значимость отдельных регрессоров — по t-статистике и p-значениям.
> *Источник: Раздел "Характеристики модели и регрессоров".*

---

### 7. Опишите метод наименьших квадратов для линейной регрессии. Опишите и сравните методы ridge regression, LASSO и эластичной сети (elastic net). Для чего в них служит регуляризация?

Предположим, что перед нами одна-единственная численная переменная y ∈ R, которую надо научиться предсказывать по нескольким входным численным переменным x
$x^⊤ = (x_1, . . . ,x_d) ∈ \R^d$; Задача линейной регрессии — построить линейную функцию:

```math
y(x,w) = w_0 + w_1x_1 + . . . + w_dx_d,
```

которая бы наилучшим образом описывала данные, выдавая линейную модель $\hat{y} = w^⊤x + b$.

* признаки $x$
* веса $w$
* свободный член $b$, часто опускают, добавляя ее как единичный признак в описании
* $\hat{y}$ предсказание модели

> 
**МНК** так и называется, что в нём минимизируется сумма квадратов
отклонений предсказанных значений $\hat{y} = w^⊤x$ от истинных значений переменной y, записанных в датасете.

> *Источник: Сергей Николенко "Машинное обучение: основы"*

```math
\min \sum (y_i - (kx_i + b))^2
```
> *Источник: Вывод формул для коэффициентов линейной регрессии методом МНК.*

**Регуляризованные методы:**
- **Ridge (L2):**
  ```math
  \min \left( \sum (y_i - \hat{y}_i)^2 + \lambda \sum \beta_j^2 \right)
  ```
- **LASSO (L1):**
  ```math
  \min \left( \sum (y_i - \hat{y}_i)^2 + \lambda \sum |\beta_j| \right)
  ```
- **Elastic Net (L1+L2):**
  ```math
  \min \left( \sum (y_i - \hat{y}_i)^2 + \lambda_1 \sum |\beta_j| + \lambda_2 \sum \beta_j^2 \right)
  ```

**Назначение регуляризации:** борьба с переобучением, снижение влияния мультиколлинеарности, отбор признаков (в LASSO).

> *Источник: Раздел "Обработка мультиколлинеарности. Факторные переменные", где регуляризация упоминается как метод борьбы с последствиями мультиколлинеарности.*

---

### 8. Что такое переобучение при регрессии? В чём оно проявляется? Как с ним бороться?

**Переобучение:** модель хорошо описывает обучающие данные, но плохо обобщает на новые.

**Проявления:** высокие MSE/R² на обучающей выборке, низкие — на тестовой.

> *Источник: Обсуждение качества модели и обобщающей способности в разделах про R² и проверку моделей.*

**Методы борьбы:**

- Регуляризация (Ridge, LASSO, Elastic Net)
- Увеличение обучающей выборки
- Упрощение модели (уменьшение числа признаков)
- Кросс-валидация

> *Источник: Методы регуляризации и отбора переменных упоминаются как способы улучшения модели.*


---

### 9. Перечислите метрики качества моделей бинарной классификации.
- Confusion Matrix (матрица ошибок): получаем сравнивая `y_true` и `y_pred` явно или по `threshold` с вероятностями
```math
ConfusionMatrix = \begin{pmatrix}
TP & FP \\
FN & TN

\end{pmatrix}
```
- Интуитивно понятной, очевидной и почти неиспользуемой метрикой является accuracy — доля правильных ответов алгоритма:
```math
Accuracy = \frac{TP + TN}{TP + TN + FP + FN}
```
- Точностью (precision) называется доля правильных ответов модели в пределах класса — это доля объектов действительно принадлежащих данному классу относительно всех объектов которые система отнесла к этому классу.
```math
Precision = \frac{TP}{TP + FP}
```
- Полнота — это доля истинно положительных классификаций. Полнота показывает, какую долю объектов, реально относящихся к положительному классу, мы предсказали верно.
```math
Recall = \frac{TP}{TP + FN}
```
- Хотелось бы иметь некую метрику которая объединяла бы в себе информацию о точности и полноте нашего алгоритма. В этом случае нам будет проще принимать решение о том какую реализацию запускать в производство (у кого больше тот и круче). Именно такой метрикой является F-мера.
```math
F_1 = \frac{2 * Precision * Recall}{Precision + Recall} = \frac{2TP}{2TP + FP + FN}
```


> *Источник: [ИФМО](https://neerc.ifmo.ru/wiki/index.php?title=%D0%9E%D1%86%D0%B5%D0%BD%D0%BA%D0%B0_%D0%BA%D0%B0%D1%87%D0%B5%D1%81%D1%82%D0%B2%D0%B0_%D0%B2_%D0%B7%D0%B0%D0%B4%D0%B0%D1%87%D0%B0%D1%85_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%86%D0%B8%D0%B8_%D0%B8_%D1%80%D0%B5%D0%B3%D1%80%D0%B5%D1%81%D1%81%D0%B8%D0%B8#.D0.9E.D1.86.D0.B5.D0.BD.D0.BA.D0.B8_.D0.BA.D0.B0.D1.87.D0.B5.D1.81.D1.82.D0.B2.D0.B0_.D0.BA.D0.BB.D0.B0.D1.81.D1.81.D0.B8.D1.84.D0.B8.D0.BA.D0.B0.D1.86.D0.B8.D0.B8)*

*Дополнительно из лекций:*
В лекциях подробно разбирается матрица ошибок (Confusion Matrix) с выделением True Positive (TP), False Positive (FP, ошибка I рода), False Negative (FN, ошибка II рода), True Negative (TN). Подчеркивается, что accuracy может вводить в заблуждение при несбалансированных классах, поэтому важны precision и recall.
> *Источник: Таблица 10 "Матрица ошибок бинарной классификации" и поясняющий текст.*

---

### 10. Задача снижения размерности. Метод главных компонент: идея и основные свойства.

**Идея:** преобразование исходных признаков в новые ортогональные (главные компоненты), максимизирующие дисперсию данных.

**Свойства:**
- Компоненты ортогональны
- Первая компонента объясняет наибольшую дисперсию
- Можно сократить размерность, сохранив заданный процент дисперсии (например, 95%)
- Чувствителен к масштабированию данных
> *Источник: Раздел "Добавление и исключение новых переменных. Метод главных компонент".*


*Дополнительно из лекций:*
Геометрическая интерпретация: поиск таких осей (компонент), чтобы разброс данных по ним был максимальным. Новые признаки линейно выражаются через старые. Часто используется для борьбы с проклятием размерности.
> *Источник: Геометрическое объяснение и цели использования PCA в том же разделе.*

---

### 11. Кластеризация. (Опишите методы агломеративной кластеризации, K-средних, DBSCAN). Как происходит оценка количества кластеров?

Кластеризация (англ. cluster analysis) — задача группировки множества объектов на подмножества (кластеры) таким образом, чтобы объекты из одного кластера были более похожи друг на друга, чем на объекты из других кластеров по какому-либо критерию.

Задача кластеризации относится к классу задач обучения без учителя.

**Агломеративная кластеризация:** иерархический метод, начинающий с отдельных точек и последовательно объединяющий ближайшие кластеры. Результат — дендрограмма.
> *Источник: Описание иерархических алгоритмов и рисунок 11 (дендрограмма).*

**K-средних:** итеративный метод, минимизирующий внутрикластерное расстояние до центроидов.

Шаги: 
1) выбор центров
2) отнесение объектов к ближайшему центру
3) пересчет центров масс
4) повтор
> *Источник: Описание алгоритма k-means в разделе "Кластеризация".*

**DBSCAN:** кластеризация на основе плотности. Выделяет основные объекты (в гуще кластера), достижимые объекты и шум (выбросы). Параметры: радиус окрестности и minPts.
> *Источник: Подробное описание алгоритма DBSCAN и классификации объектов на рисунке 13.*

Основная идея метода заключается в том, что алгоритм разделит заданный набор точек в некотором пространстве на группы точек, которые лежат друг от друга на большом расстоянии. Объекты, которые лежат отдельно от скоплений с большой плотностью, будут помечены как шумовые.

**Оценка числа кластеров:**
- Метод локтя (elbow method) по WCSS (within-cluster sum of squares)

> *Источник: Описание "принципа локтя" и рисунок 12.*

Метод локтя заключается в следующем: мы выполняем кластеризацию для различных значений k и строим график зависимости суммарной внутрикластерной дисперсии (WCSS) от количества кластеров. Внутрикластерная дисперсия (или сумма квадратов расстояний между объектами и их центроидом) показывает, насколько компактными являются кластеры. Чем меньше внутрикластерная дисперсия, тем более «упорядочены» и «однородны» кластеры.

Чтобы применить метод локтя:

- Запускаем алгоритм k-means для разных значений kkk, например от 1 до 10.

- Вычисляем внутрикластерную дисперсию для каждого значения kkk. Это можно сделать с помощью метрики, которая рассчитывает сумму квадратов расстояний между точками данных и центроидом их кластера.

- Строим график: на оси X откладываем значения kkk, а на оси Y — соответствующие значения внутрикластерной дисперсии.

- Ищем «локоть» на графике: это точка, где дальнейшее увеличение числа кластеров не приводит к значительному снижению внутрикластерной дисперсии.

> *Источник: [Habr](https://habr.com/ru/companies/skillfactory/articles/877684/)*

---

### 12. Принцип работы ансамблей решателей. Какие предъявляются требования к слабым решателям для возможности построения сильного решателя? Опишите принципы организации бэггинга (bootstrap aggregation).

**Принцип:** объединение предсказаний нескольких моделей для улучшения обобщения.
**Требования к слабым решателям:** точность > 0.5 (лучше случайного), разнообразие ошибок.
> *Источник: Теорема Кондорсе "о присяжных", приведенная в разделе "Усиление классификаторов".*

**Бэггинг:**
1. Обучение каждого классификатора на своей бутстрап-выборке (случайной подвыборке с возвращением).
2. Агрегация результатов (простое или взвешенное голосование).
**Цель:** уменьшение дисперсии ошибки.
> *Источник: Описание стратегии беггинга и схема на рисунке 9.*

*Дополнительно из лекций:*
Упоминается, что оптимальное число признаков для одного классификатора в ансамбле — sqrt(n), а объем обучающей выборки — 2/3 от общего числа объектов. Random Forest — пример алгоритма на основе бэггинга.
> *Источник: Рекомендации по параметрам в том же разделе.*

---

### 13. Объясните, что такое простое голосование, взвешенное голосование, комитет экспертов (mixture of experts) при создании ансамбля. Стекинг (stacking, stacked generalization), его основная идея и назначение.

**Простое голосование:** каждый классификатор имеет один голос, выбирается класс с большинством голосов.
**Взвешенное голосование:** голоса классификаторов взвешиваются по их качеству (частоте правильных ответов на обучающей выборке).
**Комитет экспертов:** разные модели (эксперты) специализируются на разных частях данных или типах задач, их решения комбинируются.
> *Источник: Обсуждение способов объединения классификаторов в разделе "Усиление классификаторов".*

**Стекинг:** использование метамодели (например, линейной регрессии), которая обучается на предсказаниях базовых моделей как на новых признаках. Назначение — улучшить итоговый прогноз, комбинируя сильные стороны разных алгоритмов.
> *Источник: ИИ*

---

### 14. Бустинг (boosting). Основные идеи и принципы работы AdaBoost (adaptive boosting, адаптивный бустинг).

**Идея:** последовательное обучение моделей, где каждая следующая уделяет больше внимания объектам, которые были ошибочно классифицированы предыдущими.
**Принципы работы AdaBoost:**
1. Начальные веса всех объектов обучающей выборки равны.
2. На каждой итерации:
   - Обучается слабый классификатор на данных с текущими весами.
   - Вычисляется его взвешенная ошибка.
   - Вычисляется вес этого классификатора в итоговом ансамбле (чем меньше ошибка, тем больше вес).
   - Увеличиваются веса объектов, которые были классифицированы неверно.
3. Итоговый классификатор — взвешенная сумма (или взвешенное голосование) всех слабых классификаторов.
> *Источник: Общее описание концепции бустинга и адаптивного изменения весов объектов в разделе "Усиление классификаторов".*

---

### 15. Бустинг (boosting). Основные идеи и принципы работы градиентного бустинга (gradient boost).

**Идея:** последовательная минимизация функции потерь через градиентный спуск в пространстве функций (моделей).
**Принципы работы:**
1. Начинаем с начального простого предсказания (например, константа, равная среднему значению целевой переменной).
2. На каждом шаге (для каждой добавляемой модели):
   - Вычисляются остатки (псевдо-остатки) — градиенты функции потерь по текущему предсказанию.
   - Новая слабая модель (часто дерево решений) обучается предсказывать эти остатки.
   - Предсказание этой модели, умноженное на коэффициент обучения (шаг), добавляется к текущему общему предсказанию.
3. Процесс повторяется заданное число раз или до сходимости.
**Ключевое отличие от AdaBoost:** явная минимизация дифференцируемой функции потерь, а не перевзвешивание объектов.
> *Источник: ИИ*

---

### 16. Балансирование наборов данных: проблема несбалансированных данных и методы её преодоления

**Проблема:** один класс (мажоритарный) значительно преобладает над другим (миноритарным), что приводит к смещению модели в сторону частого класса и плохому распознаванию редкого.

> *Источник: Пример с accuracy 90% для тривиального классификатора в разделе "Меры точности классификаторов".*

**Методы:**

- **Взвешивание классов (class weighting):** назначение большей штрафной стоимости за ошибку на объекте миноритарного класса в функции потерь.

- **Undersampling:** случайное удаление части объектов мажоритарного класса.

- **Oversampling:** дублирование объектов миноритарного класса или генерация синтетических примеров (например, SMOTE).

- **Использование метрик, устойчивых к дисбалансу:** F1-score, Precision-Recall AUC, Matthews Correlation Coefficient (MCC) вместо Accuracy.

> *Источник: Обсуждение недостатка accuracy и необходимости других метрик косвенно указывает на проблему дисбаланса. Конкретные методы балансировки являются стандартными и логично дополняют материал.*

---

### 17. Деревья решений. Процесс построения. Регуляризация деревьев решений.

**Процесс построения:**

1. Начиная с корневого узла, содержащего всю выборку.

2. Для каждого узла выбирается признак и пороговое значение, которые наилучшим образом разделяют данные в этом узле на два подмножества.

3. **Критерий разделения:** максимизация чистоты дочерних узлов. Чаще всего используются:
   - **Критерий Джини (Gini impurity):** мера расслоения.
   - **Информационный выигрыш (Information Gain)** на основе энтропии Шеннона: каждый вопрос должен максимально снижать неопределенность (энтропию) системы.

4. Процесс рекурсивно повторяется для каждого дочернего узла, пока не будет выполнено условие остановки.
> *Источник: Раздел "Дерево принятия решений", включая описание критериев Джини и энтропии.*

**Регуляризация (для борьбы с переобучением):**
- Ограничение максимальной глубины дерева (`max_depth`).
- Задание минимального числа объектов в листе (`min_samples_leaf`).
- Задание минимального числа объектов для разделения узла (`min_samples_split`).
- Ограничение максимального числа листьев (`max_leaf_nodes`).
- **Обрезка (pruning):** построение полного дерева с последующим удалением узлов, дающих незначительный прирост качества.
> *Источник: Упоминание параметров `max_leaf_nodes` и `max_depth` в Коде 4 и обсуждение переобучения.*

---

### 18. Что такое случайный лес (random forest)? Для чего в него введена случайность? В чём она состоит и как влияет на методы построения случайного леса?

**Случайный лес:** ансамбль решающих деревьев, построенный на принципах **бэггинга** (bootstrap aggregation) с добавлением **случайности в выборе признаков**.
> *Источник: Упоминание Random Forest как примера алгоритма на основе бэггинга в разделе "Усиление классификаторов".*

**Цель введения случайности:**
- Уменьшение **корреляции между деревьями** в ансамбле.
- Повышение **обобщающей способности** модели.
- Борьба с **переобучением**, которому подвержены отдельные глубокие деревья.

**В чём состоит случайность:**
1. **Bootstrap-выборки:** каждое дерево обучается на своей случайной подвыборке данных, взятой с возвращением из исходного набора. Это создает разнообразие обучающих множеств.
2. **Случайный выбор признаков:** при поиске лучшего разделения в каждом узле дерева рассматривается не весь набор признаков, а только случайное подмножество из них (обычно размером `sqrt(n_features)`).

**Влияние на построение:**
- Каждое дерево строится независимо и параллельно.
- Деревья могут быть построены глубокими (с низким смещением), так как высокая дисперсия их ошибок затем усредняется в ансамбле.
- Итоговый прогноз формируется путем **усреднения** (для регрессии) или **голосования** (для классификации) предсказаний всех деревьев.
> *Источник: Объединение принципов бэггинга (раздел "Усиление классификаторов") и идеи случайного подмножества признаков, упомянутой в том же разделе.*
